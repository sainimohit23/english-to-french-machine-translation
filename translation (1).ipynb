{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"translation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"WlPSxo20j3Ij","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2366},"outputId":"33ad6c36-1c2b-4720-d50d-09af2aa38f4c","executionInfo":{"status":"ok","timestamp":1535142369333,"user_tz":-330,"elapsed":115008,"user":{"displayName":"hemlata saini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"105515696648587539159"}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Preconfiguring packages ...\n","Selecting previously unselected package cron.\n","(Reading database ... 18408 files and directories currently installed.)\n","Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n","Unpacking cron (3.0pl1-128ubuntu5) ...\n","Selecting previously unselected package libapparmor1:amd64.\n","Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n","Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n","Selecting previously unselected package libdbus-1-3:amd64.\n","Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n","Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n","Selecting previously unselected package dbus.\n","Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n","Unpacking dbus (1.10.22-1ubuntu1) ...\n","Selecting previously unselected package dirmngr.\n","Preparing to unpack .../04-dirmngr_2.1.15-1ubuntu8.1_amd64.deb ...\n","Unpacking dirmngr (2.1.15-1ubuntu8.1) ...\n","Selecting previously unselected package distro-info-data.\n","Preparing to unpack .../05-distro-info-data_0.36ubuntu0.2_all.deb ...\n","Unpacking distro-info-data (0.36ubuntu0.2) ...\n","Selecting previously unselected package libkmod2:amd64.\n","Preparing to unpack .../06-libkmod2_24-1ubuntu2_amd64.deb ...\n","Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n","Selecting previously unselected package kmod.\n","Preparing to unpack .../07-kmod_24-1ubuntu2_amd64.deb ...\n","Unpacking kmod (24-1ubuntu2) ...\n","Selecting previously unselected package lsb-release.\n","Preparing to unpack .../08-lsb-release_9.20160110ubuntu5_all.deb ...\n","Unpacking lsb-release (9.20160110ubuntu5) ...\n","Selecting previously unselected package libgirepository-1.0-1:amd64.\n","Preparing to unpack .../09-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n","Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n","Selecting previously unselected package gir1.2-glib-2.0:amd64.\n","Preparing to unpack .../10-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n","Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n","Selecting previously unselected package iso-codes.\n","Preparing to unpack .../11-iso-codes_3.75-1_all.deb ...\n","Unpacking iso-codes (3.75-1) ...\n","Selecting previously unselected package libdbus-glib-1-2:amd64.\n","Preparing to unpack .../12-libdbus-glib-1-2_0.108-2_amd64.deb ...\n","Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n","Selecting previously unselected package python-apt-common.\n","Preparing to unpack .../13-python-apt-common_1.4.0~beta3build2_all.deb ...\n","Unpacking python-apt-common (1.4.0~beta3build2) ...\n","Selecting previously unselected package python3-apt.\n","Preparing to unpack .../14-python3-apt_1.4.0~beta3build2_amd64.deb ...\n","Unpacking python3-apt (1.4.0~beta3build2) ...\n","Selecting previously unselected package python3-dbus.\n","Preparing to unpack .../15-python3-dbus_1.2.4-1build3_amd64.deb ...\n","Unpacking python3-dbus (1.2.4-1build3) ...\n","Selecting previously unselected package python3-gi.\n","Preparing to unpack .../16-python3-gi_3.24.1-2build1_amd64.deb ...\n","Unpacking python3-gi (3.24.1-2build1) ...\n","Selecting previously unselected package module-init-tools.\n","Preparing to unpack .../17-module-init-tools_24-1ubuntu2_all.deb ...\n","Unpacking module-init-tools (24-1ubuntu2) ...\n","Selecting previously unselected package python-apt.\n","Preparing to unpack .../18-python-apt_1.4.0~beta3build2_amd64.deb ...\n","Unpacking python-apt (1.4.0~beta3build2) ...\n","Selecting previously unselected package python-pycurl.\n","Preparing to unpack .../19-python-pycurl_7.43.0-2build2_amd64.deb ...\n","Unpacking python-pycurl (7.43.0-2build2) ...\n","Selecting previously unselected package python-software-properties.\n","Preparing to unpack .../20-python-software-properties_0.96.24.17_all.deb ...\n","Unpacking python-software-properties (0.96.24.17) ...\n","Selecting previously unselected package python3-software-properties.\n","Preparing to unpack .../21-python3-software-properties_0.96.24.17_all.deb ...\n","Unpacking python3-software-properties (0.96.24.17) ...\n","Selecting previously unselected package software-properties-common.\n","Preparing to unpack .../22-software-properties-common_0.96.24.17_all.deb ...\n","Unpacking software-properties-common (0.96.24.17) ...\n","Selecting previously unselected package unattended-upgrades.\n","Preparing to unpack .../23-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n","Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n","Setting up python-apt-common (1.4.0~beta3build2) ...\n","Setting up python3-apt (1.4.0~beta3build2) ...\n","Setting up iso-codes (3.75-1) ...\n","Setting up distro-info-data (0.36ubuntu0.2) ...\n","Setting up python-pycurl (7.43.0-2build2) ...\n","Setting up lsb-release (9.20160110ubuntu5) ...\n","Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n","Setting up libkmod2:amd64 (24-1ubuntu2) ...\n","Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n","Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n","Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n","Setting up unattended-upgrades (0.98ubuntu1.1) ...\n","\n","Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n","\n","Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Setting up dirmngr (2.1.15-1ubuntu8.1) ...\n","Setting up cron (3.0pl1-128ubuntu5) ...\n","Adding group `crontab' (GID 102) ...\n","Done.\n","update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n","update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n","Setting up kmod (24-1ubuntu2) ...\n","Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n","Setting up python3-gi (3.24.1-2build1) ...\n","Setting up module-init-tools (24-1ubuntu2) ...\n","Setting up python3-software-properties (0.96.24.17) ...\n","Setting up dbus (1.10.22-1ubuntu1) ...\n","Setting up python-apt (1.4.0~beta3build2) ...\n","Setting up python3-dbus (1.2.4-1build3) ...\n","Setting up python-software-properties (0.96.24.17) ...\n","Setting up software-properties-common (0.96.24.17) ...\n","Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n","Processing triggers for dbus (1.10.22-1ubuntu1) ...\n","gpg: keybox '/tmp/tmpl4bi433l/pubring.gpg' created\n","gpg: /tmp/tmpl4bi433l/trustdb.gpg: trustdb created\n","gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n","gpg: Total number processed: 1\n","gpg:               imported: 1\n","Warning: apt-key output should not be parsed (stdout is not a terminal)\n","Selecting previously unselected package libfuse2:amd64.\n","(Reading database ... 19816 files and directories currently installed.)\n","Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n","Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n","Selecting previously unselected package fuse.\n","Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n","Unpacking fuse (2.9.7-1ubuntu1) ...\n","Selecting previously unselected package google-drive-ocamlfuse.\n","Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n","Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n","Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n","Setting up fuse (2.9.7-1ubuntu1) ...\n","Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"D2yWEv2Tj5Mq","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mnpsrcJiryam","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"VyFtT1VZk_hq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":6715},"outputId":"728bc614-62dd-4623-c9ea-2684de8754ed"},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import pickle\n","import datetime\n","\n","def load_preprocess():\n","    with open('drive/preprocess_en_fr.p', mode='rb') as in_file:\n","        return pickle.load(in_file)\n","\n","\n","(source_int_text, target_int_text), (source_int_to_vocab, target_int_to_vocab) , (source_vocab_to_int, target_vocab_to_int) = load_preprocess()\n","\n","# =============================================================================\n","#       STEPS INVOLVED:\n","\n","#     (1) define input parameters to the encoder model\n","#         enc_dec_model_inputs\n","#     (2) build encoder model\n","#         encoding_layer\n","#     (3) define input parameters to the decoder model\n","#         enc_dec_model_inputs, process_decoder_input, decoding_layer\n","#     (4) build decoder model for training\n","#         decoding_layer_train\n","#     (5) build decoder model for inference\n","#         decoding_layer_infer\n","#     (6) put (4) and (5) together\n","#         decoding_layer\n","#     (7) connect encoder and decoder models\n","#         seq2seq_model\n","#     (8) train and estimate loss and accuracy\n","# \n","# =============================================================================\n","\n","def enc_dec_model_inputs():\n","    inputs = tf.placeholder(tf.int32, [None, None], name='input')\n","    targets = tf.placeholder(tf.int32, [None, None], name='targets') \n","    \n","    target_sequence_length = tf.placeholder(tf.int32, [None], name='target_sequence_length')\n","    source_sequence_length = tf.placeholder(tf.int32, [None], name='target_sequence_length')\n","    max_target_len = tf.reduce_max(target_sequence_length)    \n","    \n","    return inputs, targets, target_sequence_length, max_target_len, source_sequence_length\n","\n","def hyperparam_inputs():\n","    lr_rate = tf.placeholder(tf.float32, name='lr_rate')\n","    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n","    \n","    return lr_rate, keep_prob\n","\n","def process_decoder_input(target_data, target_vocab_to_int, batch_size):\n","    \"\"\"\n","    Preprocess target data for encoding\n","    :return: Preprocessed target data\n","    \"\"\"\n","    # get '<GO>' id\n","    go_id = target_vocab_to_int['<GO>']\n","    \n","    after_slice = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n","    after_concat = tf.concat( [tf.fill([batch_size, 1], go_id), after_slice], 1)\n","    \n","    return after_concat\n","\n","\n","def encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob, \n","                   source_vocab_size, \n","                   encoding_embedding_size,\n","                   source_sequence_length):\n","    \"\"\"\n","    :return: tuple (RNN output, RNN state)\n","    \"\"\"\n","    embed = tf.contrib.layers.embed_sequence(rnn_inputs, \n","                                             vocab_size=source_vocab_size, \n","                                             embed_dim=encoding_embedding_size)\n","    \n","    stacked_cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(rnn_size), keep_prob) for _ in range(num_layers)])\n","    \n","    outputs, state = tf.nn.bidirectional_dynamic_rnn(cell_fw=stacked_cells, \n","                                                             cell_bw=stacked_cells, \n","                                                             inputs=embed, \n","                                                             sequence_length=source_sequence_length, \n","                                                             dtype=tf.float32)\n","    \n","    concat_outputs = tf.concat(outputs, 2)\n","    return concat_outputs, state\n","\n","def decoding_layer_train(encoder_outputs, encoder_state, dec_cell, dec_embed_input, \n","                         target_sequence_length, max_summary_length, \n","                         output_layer, keep_prob):\n","    \"\"\"\n","    Create a training process in decoding layer \n","    :return: BasicDecoderOutput containing training logits and sample_id\n","    \"\"\"\n","    \n","    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, \n","                                             output_keep_prob=keep_prob)\n","    \n","    \n","    train_helper = tf.contrib.seq2seq.TrainingHelper(dec_embed_input, target_sequence_length)\n","    \n","    attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(rnn_size, encoder_outputs,\n","                                                               memory_sequence_length=target_sequence_length)\n","    \n","    attention_cell = tf.contrib.seq2seq.AttentionWrapper(dec_cell, attention_mechanism,\n","                                                         attention_layer_size=rnn_size/2)\n","    \n","    decoder = tf.contrib.seq2seq.BasicDecoder(cell=attention_cell, helper=train_helper, \n","                                              initial_state=attention_cell.zero_state(dtype=tf.float32, batch_size=batch_size),\n","                                              output_layer=output_layer) \n","    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, impute_finished=True, maximum_iterations=max_summary_length)\n","    \n","    return outputs\n","\n","\n","\n","def decoding_layer_infer(encoder_outputs, encoder_state, dec_cell,\n","                         dec_embeddings, start_of_sequence_id,\n","                         end_of_sequence_id, max_target_sequence_length,\n","                         vocab_size, output_layer, batch_size, keep_prob,\n","                         target_sequence_length):\n","    \"\"\"\n","    Create a inference process in decoding layer \n","    :return: BasicDecoderOutput containing inference logits and sample_id\n","    \"\"\"\n","    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, \n","                                             output_keep_prob=keep_prob)\n","    \n","    infer_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(dec_embeddings, \n","                                                      tf.fill([batch_size], start_of_sequence_id), \n","                                                      end_of_sequence_id)\n","    \n","    attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(rnn_size, encoder_outputs,\n","                                                               memory_sequence_length=target_sequence_length)\n","    \n","    attention_cell = tf.contrib.seq2seq.AttentionWrapper(dec_cell, attention_mechanism,\n","                                                         attention_layer_size=rnn_size/2)\n","    \n","    decoder = tf.contrib.seq2seq.BasicDecoder(cell=attention_cell, helper=infer_helper, \n","                                              initial_state=attention_cell.zero_state(dtype=tf.float32, batch_size=batch_size),\n","                                              output_layer=output_layer)\n","   \n","    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, impute_finished=True, maximum_iterations=max_target_sequence_length)\n","    \n","    return outputs\n","\n","def decoding_layer(encoder_outputs, dec_input, encoder_state,\n","                   target_sequence_length, max_target_sequence_length,\n","                   rnn_size,\n","                   num_layers, target_vocab_to_int, target_vocab_size,\n","                   batch_size, keep_prob, decoding_embedding_size):\n","    \"\"\"\n","    Create decoding layer\n","    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n","    \"\"\"\n","    target_vocab_size = len(target_vocab_to_int) + 1\n","    dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n","    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n","    \n","    cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(rnn_size) for _ in range(num_layers)])\n","    \n","    with tf.variable_scope(\"decode\"):\n","        output_layer = tf.layers.Dense(target_vocab_size)\n","        train_output = decoding_layer_train(encoder_outputs,\n","                                            encoder_state, \n","                                            cells, \n","                                            dec_embed_input, \n","                                            target_sequence_length, \n","                                            max_target_sequence_length, \n","                                            output_layer, \n","                                            keep_prob)\n","\n","    with tf.variable_scope(\"decode\", reuse=True):\n","        infer_output = decoding_layer_infer(encoder_outputs,\n","                                            encoder_state, \n","                                            cells, \n","                                            dec_embeddings, \n","                                            target_vocab_to_int['<GO>'], \n","                                            target_vocab_to_int['<EOS>'], \n","                                            max_target_sequence_length, \n","                                            target_vocab_size, \n","                                            output_layer,\n","                                            batch_size,\n","                                            keep_prob,\n","                                            target_sequence_length)\n","\n","    return (train_output, infer_output)\n","\n","def seq2seq_model(input_data, target_data, keep_prob, batch_size,\n","                  target_sequence_length,\n","                  max_target_sentence_length,\n","                  source_vocab_size, target_vocab_size,\n","                  enc_embedding_size, dec_embedding_size,\n","                  rnn_size, num_layers, target_vocab_to_int,\n","                  source_sequence_length):\n","    \"\"\"\n","    Build the Sequence-to-Sequence model\n","    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n","    \"\"\"\n","    enc_outputs, enc_states = encoding_layer(input_data, \n","                                             rnn_size, \n","                                             num_layers, \n","                                             keep_prob, \n","                                             source_vocab_size, \n","                                             enc_embedding_size,\n","                                             source_sequence_length)\n","    \n","    dec_input = process_decoder_input(target_data, \n","                                      target_vocab_to_int, \n","                                      batch_size)\n","    \n","    train_output, infer_output = decoding_layer(enc_outputs,\n","                                                dec_input,\n","                                               enc_states, \n","                                               target_sequence_length, \n","                                               max_target_sentence_length,\n","                                               rnn_size,\n","                                              num_layers,\n","                                              target_vocab_to_int,\n","                                              target_vocab_size,\n","                                              batch_size,\n","                                              keep_prob,\n","                                              dec_embedding_size)\n","    \n","    return train_output, infer_output\n","\n","\n","display_step = 30\n","\n","epochs = 100\n","batch_size = 32\n","\n","rnn_size = 128\n","num_layers = 3\n","\n","encoding_embedding_size = 200\n","decoding_embedding_size = 200\n","\n","learning_rate = 0.001\n","learning_rate_decay = 0.9\n","min_learning_rate = 0.0001\n","keep_probability = 0.5\n","\n","save_path = 'checkpoints/dev'\n","(source_int_text, target_int_text), _, (source_vocab_to_int, target_vocab_to_int) = load_preprocess()\n","max_target_sentence_length = max([len(sentence) for sentence in source_int_text])\n","\n","train_graph = tf.Graph()\n","with train_graph.as_default():\n","    input_data, targets, target_sequence_length, max_target_sequence_length, source_sequence_length = enc_dec_model_inputs()\n","    lr, keep_prob = hyperparam_inputs()\n","    \n","    train_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),\n","                                                   targets,\n","                                                   keep_prob,\n","                                                   batch_size,\n","                                                   target_sequence_length,\n","                                                   max_target_sequence_length,\n","                                                   len(source_vocab_to_int),\n","                                                   len(target_vocab_to_int),\n","                                                   encoding_embedding_size,\n","                                                   decoding_embedding_size,\n","                                                   rnn_size,\n","                                                   num_layers,\n","                                                   target_vocab_to_int,\n","                                                   source_sequence_length)\n","    \n","    training_logits = tf.identity(train_logits.rnn_output, name='logits')\n","    inference_logits = tf.identity(inference_logits.sample_id, name='predictions')\n","\n","    # https://www.tensorflow.org/api_docs/python/tf/sequence_mask\n","    # - Returns a mask tensor representing the first N positions of each cell.\n","    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length, dtype=tf.float32, name='masks')\n","    \n","    \n","\n","    with tf.name_scope(\"optimization\"):\n","        # Loss function - weighted softmax cross entropy\n","        cost = tf.contrib.seq2seq.sequence_loss(\n","            training_logits,\n","            targets,\n","            masks)\n","\n","        # Optimizer\n","        optimizer = tf.train.AdamOptimizer(lr)\n","\n","        # Gradient Clipping\n","        gradients = optimizer.compute_gradients(cost)\n","        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n","        train_op = optimizer.apply_gradients(capped_gradients)\n","        \n","        tf.summary.scalar('loss', cost)\n","        merged = tf.summary.merge_all()\n","        logdir = 'tensorboard/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\" \n","        \n","        \n","def pad_sentence_batch(sentence_batch, pad_int):\n","    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n","    max_sentence = max([len(sentence) for sentence in sentence_batch])\n","    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]\n","\n","\n","def get_batches(sources, targets, batch_size, source_pad_int, target_pad_int):\n","    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n","    for batch_i in range(0, len(sources)//batch_size):\n","        start_i = batch_i * batch_size\n","\n","        # Slice the right amount for the batch\n","        sources_batch = sources[start_i:start_i + batch_size]\n","        targets_batch = targets[start_i:start_i + batch_size]\n","\n","        # Pad\n","        pad_sources_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n","        pad_targets_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n","\n","        # Need the lengths for the _lengths parameters\n","        pad_targets_lengths = []\n","        for target in pad_targets_batch:\n","            pad_targets_lengths.append(len(target))\n","\n","        pad_source_lengths = []\n","        for source in pad_sources_batch:\n","            pad_source_lengths.append(len(source))\n","\n","        yield pad_sources_batch, pad_targets_batch, pad_source_lengths, pad_targets_lengths\n","        \n","        \n","def get_accuracy(target, logits):\n","    \"\"\"\n","    Calculate accuracy\n","    \"\"\"\n","    max_seq = max(target.shape[1], logits.shape[1])\n","    if max_seq - target.shape[1]:\n","        target = np.pad(\n","            target,\n","            [(0,0),(0,max_seq - target.shape[1])],\n","            'constant')\n","    if max_seq - logits.shape[1]:\n","        logits = np.pad(\n","            logits,\n","            [(0,0),(0,max_seq - logits.shape[1])],\n","            'constant')\n","\n","    return np.mean(np.equal(target, logits))\n","\n","\n","\n","def sentence_to_seq(sentence, vocab_to_int):\n","    results = []\n","    for word in sentence.split(\" \"):\n","        if word in vocab_to_int:\n","            results.append(vocab_to_int[word])\n","        else:\n","            results.append(vocab_to_int['<UNK>'])\n","            \n","    return results\n","\n","sentances = [\"how are you\",\n","             \"what are you doing\",\n","             \"get up\",\n","             \"go there\",\n","             \"want some food\"]\n","\n","\n","# Split data to training and validation sets\n","train_source = source_int_text[batch_size:]\n","train_target = target_int_text[batch_size:]\n","valid_source = source_int_text[:batch_size]\n","valid_target = target_int_text[:batch_size]\n","(valid_sources_batch, valid_targets_batch, valid_sources_lengths, valid_targets_lengths ) = next(get_batches(valid_source,\n","                                                                                                             valid_target,\n","                                                                                                             batch_size,\n","                                                                                                             source_vocab_to_int['<PAD>'],\n","                                                                                                             target_vocab_to_int['<PAD>']))\n","\n","\n","\n","with tf.Session(graph=train_graph) as sess:\n","  writer = tf.summary.FileWriter(logdir, train_graph)\n","  saver = tf.train.Saver()\n","  try:\n","      saver.restore(sess, tf.train.latest_checkpoint('drive/checkpoints/'))\n","      print(\"Saved model found\")\n","  except ValueError:\n","      print(\"No saved models found, initializing new variables\")\n","      sess.run(tf.global_variables_initializer())\n","\n","  for epoch_i in range(31,epochs):\n","      for batch_i, (source_batch, target_batch, sources_lengths, targets_lengths) in enumerate(\n","              get_batches(train_source, train_target, batch_size,\n","                          source_vocab_to_int['<PAD>'],\n","                          target_vocab_to_int['<PAD>'])):\n","\n","          _, loss = sess.run(\n","              [train_op, cost],\n","              {input_data: source_batch,\n","               targets: target_batch,\n","               lr: learning_rate,\n","               target_sequence_length: targets_lengths,\n","               keep_prob: keep_probability,\n","               source_sequence_length: sources_lengths})\n","\n","\n","          if batch_i % display_step == 0 and batch_i > 0:\n","              batch_train_logits = sess.run(\n","                  inference_logits,\n","                  {input_data: source_batch,\n","                   target_sequence_length: targets_lengths,\n","                   keep_prob: 1.0,\n","                   source_sequence_length: sources_lengths})\n","\n","              batch_valid_logits = sess.run(\n","                  inference_logits,\n","                  {input_data: valid_sources_batch,\n","                   target_sequence_length: valid_targets_lengths,\n","                   keep_prob: 1.0,\n","                   source_sequence_length: valid_sources_lengths})\n","\n","              train_acc = get_accuracy(target_batch, batch_train_logits)\n","              valid_acc = get_accuracy(valid_targets_batch, batch_valid_logits)       \n","\n","\n","              print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.4f}, Validation Accuracy: {:>6.4f}, Loss: {:>6.4f}'\n","                    .format(epoch_i, batch_i, len(source_int_text) // batch_size, train_acc, valid_acc, loss))\n","\n","\n","          if batch_i%30 == 0 and batch_i > 0:\n","              idx = np.random.randint(0,5)\n","              st = sentence_to_seq(sentances[idx], source_vocab_to_int)\n","\n","              trans_logits = sess.run(inference_logits, feed_dict={input_data: [st]*batch_size,\n","                                       target_sequence_length: [len(st)*2]*batch_size,\n","                                       source_sequence_length: [len(st)*2]*batch_size,\n","                                       keep_prob: 1.0})[0]\n","              cst = sess.run(merged,{input_data: source_batch,\n","                                   targets: target_batch,\n","                                   lr: learning_rate,\n","                                   target_sequence_length: targets_lengths,\n","                                   source_sequence_length: sources_lengths,\n","                                   keep_prob: keep_probability})\n","              writer.add_summary(cst, batch_i)                \n","\n","              print('Input')\n","              print('  Word Ids:      {}'.format([i for i in st]))\n","              print('  input : {}'.format([source_int_to_vocab[i] for i in st]))\n","\n","              print('\\nPrediction')\n","              print('  Word Ids:      {}'.format([i for i in trans_logits]))\n","              print('  reply: {}'.format(\" \".join([target_int_to_vocab[i] for i in trans_logits])))\n","\n","     # learning_rate *= learning_rate_decay\n","     # if learning_rate < min_learning_rate:\n","      #    learning_rate = min_learning_rate\n","      # Save Model\n","      if epoch_i%5 == 0:\n","          saver.save(sess, 'drive/checkpoints/dev',epoch_i)\n","          print('Model Trained and Saved')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from drive/checkpoints/dev-40\n","Saved model found\n","Epoch  31 Batch   30/8076 - Train Accuracy: 0.1632, Validation Accuracy: 0.2188, Loss: 1.1386\n","Input\n","  Word Ids:      [13581, 3441, 1271, 18321]\n","  input : ['what', 'are', 'you', 'doing']\n","\n","Prediction\n","  Word Ids:      [32633, 7083, 29483, 50242, 0, 0, 0, 0]\n","  reply: je vous remercie <EOS> dlocalisations dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch   60/8076 - Train Accuracy: 0.4062, Validation Accuracy: 0.1719, Loss: 0.8060\n","Input\n","  Word Ids:      [30590, 17471]\n","  input : ['go', 'there']\n","\n","Prediction\n","  Word Ids:      [30387, 35686, 46830, 50242]\n","  reply: nous le comprenons <EOS>\n","Epoch  31 Batch   90/8076 - Train Accuracy: 0.3320, Validation Accuracy: 0.1510, Loss: 0.8532\n","Input\n","  Word Ids:      [13581, 3441, 1271, 18321]\n","  input : ['what', 'are', 'you', 'doing']\n","\n","Prediction\n","  Word Ids:      [39317, 22998, 50242, 0, 0]\n","  reply: que faitesvous <EOS> dlocalisations dlocalisations\n","Epoch  31 Batch  120/8076 - Train Accuracy: 0.2674, Validation Accuracy: 0.2604, Loss: 0.8086\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [48110, 7083, 50242, 0, 0, 0]\n","  reply: comment vous <EOS> dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch  150/8076 - Train Accuracy: 0.2386, Validation Accuracy: 0.1458, Loss: 0.7226\n","Input\n","  Word Ids:      [16892, 33605]\n","  input : ['get', 'up']\n","\n","Prediction\n","  Word Ids:      [30387, 47458, 50184, 16568]\n","  reply: nous avons besoin de\n","Epoch  31 Batch  180/8076 - Train Accuracy: 0.2687, Validation Accuracy: 0.2604, Loss: 0.9692\n","Input\n","  Word Ids:      [10225, 18602, 21422]\n","  input : ['want', 'some', 'food']\n","\n","Prediction\n","  Word Ids:      [31969, 47785, 27581, 13162, 47785, 27581]\n","  reply: voulons un aliments pour un aliments\n","Epoch  31 Batch  210/8076 - Train Accuracy: 0.4018, Validation Accuracy: 0.1562, Loss: 1.0332\n","Input\n","  Word Ids:      [16892, 33605]\n","  input : ['get', 'up']\n","\n","Prediction\n","  Word Ids:      [30387, 47458, 50184, 16568]\n","  reply: nous avons besoin de\n","Epoch  31 Batch  240/8076 - Train Accuracy: 0.3250, Validation Accuracy: 0.1354, Loss: 0.6186\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [48110, 7083, 50242, 0, 0]\n","  reply: comment vous <EOS> dlocalisations dlocalisations\n","Epoch  31 Batch  270/8076 - Train Accuracy: 0.3160, Validation Accuracy: 0.1562, Loss: 0.8453\n","Input\n","  Word Ids:      [13581, 3441, 1271, 18321]\n","  input : ['what', 'are', 'you', 'doing']\n","\n","Prediction\n","  Word Ids:      [39317, 22998, 50242, 0, 0, 0, 0, 0]\n","  reply: que faitesvous <EOS> dlocalisations dlocalisations dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch  300/8076 - Train Accuracy: 0.3789, Validation Accuracy: 0.2656, Loss: 0.7567\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [48110, 7083, 50242, 0, 0, 0]\n","  reply: comment vous <EOS> dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch  330/8076 - Train Accuracy: 0.2906, Validation Accuracy: 0.1510, Loss: 0.7414\n","Input\n","  Word Ids:      [10225, 18602, 21422]\n","  input : ['want', 'some', 'food']\n","\n","Prediction\n","  Word Ids:      [31969, 1099, 27581, 50242, 0, 0]\n","  reply: voulons une aliments <EOS> dlocalisations dlocalisations\n","Epoch  31 Batch  360/8076 - Train Accuracy: 0.2955, Validation Accuracy: 0.2344, Loss: 0.7154\n","Input\n","  Word Ids:      [16892, 33605]\n","  input : ['get', 'up']\n","\n","Prediction\n","  Word Ids:      [30387, 47458, 50184, 16568]\n","  reply: nous avons besoin de\n","Epoch  31 Batch  390/8076 - Train Accuracy: 0.1583, Validation Accuracy: 0.1458, Loss: 0.8308\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [48110, 7083, 50242, 0, 0, 0]\n","  reply: comment vous <EOS> dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch  420/8076 - Train Accuracy: 0.1847, Validation Accuracy: 0.2188, Loss: 1.1609\n","Input\n","  Word Ids:      [13581, 3441, 1271, 18321]\n","  input : ['what', 'are', 'you', 'doing']\n","\n","Prediction\n","  Word Ids:      [39317, 7083, 22051, 50242, 0, 0, 0, 0]\n","  reply: que vous faites <EOS> dlocalisations dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch  450/8076 - Train Accuracy: 0.3542, Validation Accuracy: 0.1354, Loss: 1.0950\n","Input\n","  Word Ids:      [13581, 3441, 1271, 18321]\n","  input : ['what', 'are', 'you', 'doing']\n","\n","Prediction\n","  Word Ids:      [39317, 7083, 22051, 50242, 0, 0]\n","  reply: que vous faites <EOS> dlocalisations dlocalisations\n","Epoch  31 Batch  480/8076 - Train Accuracy: 0.1781, Validation Accuracy: 0.2292, Loss: 1.2175\n","Input\n","  Word Ids:      [16892, 33605]\n","  input : ['get', 'up']\n","\n","Prediction\n","  Word Ids:      [30387, 47458, 50184, 16568]\n","  reply: nous avons besoin de\n","Epoch  31 Batch  510/8076 - Train Accuracy: 0.2091, Validation Accuracy: 0.1042, Loss: 1.2477\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [48110, 7083, 50242, 0, 0]\n","  reply: comment vous <EOS> dlocalisations dlocalisations\n","Epoch  31 Batch  540/8076 - Train Accuracy: 0.1629, Validation Accuracy: 0.1875, Loss: 0.7866\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [48110, 7083, 50242, 0, 0, 0]\n","  reply: comment vous <EOS> dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch  570/8076 - Train Accuracy: 0.1342, Validation Accuracy: 0.1927, Loss: 1.0255\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [48110, 7083, 50242, 0, 0, 0]\n","  reply: comment vous <EOS> dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch  600/8076 - Train Accuracy: 0.2301, Validation Accuracy: 0.2083, Loss: 1.0412\n","Input\n","  Word Ids:      [13581, 3441, 1271, 18321]\n","  input : ['what', 'are', 'you', 'doing']\n","\n","Prediction\n","  Word Ids:      [39317, 6653, 50242, 0, 0, 0, 0, 0]\n","  reply: que faire <EOS> dlocalisations dlocalisations dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch  630/8076 - Train Accuracy: 0.2569, Validation Accuracy: 0.2031, Loss: 1.5407\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [48110, 7083, 50242, 0, 0, 0]\n","  reply: comment vous <EOS> dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch  660/8076 - Train Accuracy: 0.1849, Validation Accuracy: 0.1979, Loss: 1.3025\n","Input\n","  Word Ids:      [30590, 17471]\n","  input : ['go', 'there']\n","\n","Prediction\n","  Word Ids:      [30387, 47458, 50184, 16568]\n","  reply: nous avons besoin de\n","Epoch  31 Batch  690/8076 - Train Accuracy: 0.2214, Validation Accuracy: 0.1823, Loss: 1.3045\n","Input\n","  Word Ids:      [10225, 18602, 21422]\n","  input : ['want', 'some', 'food']\n","\n","Prediction\n","  Word Ids:      [17916, 43428, 42218, 41661, 11095, 50242]\n","  reply: la scurit est en effet <EOS>\n","Epoch  31 Batch  720/8076 - Train Accuracy: 0.1364, Validation Accuracy: 0.1927, Loss: 1.5388\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [375, 39317, 12497, 42218, 13413, 50242]\n","  reply: estce que cela est bien <EOS>\n","Epoch  31 Batch  750/8076 - Train Accuracy: 0.2614, Validation Accuracy: 0.1823, Loss: 1.1846\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [375, 39317, 12497, 42218, 13413, 50242]\n","  reply: estce que cela est bien <EOS>\n","Epoch  31 Batch  780/8076 - Train Accuracy: 0.2212, Validation Accuracy: 0.1719, Loss: 0.9798\n","Input\n","  Word Ids:      [30590, 17471]\n","  input : ['go', 'there']\n","\n","Prediction\n","  Word Ids:      [30387, 47458, 50184, 16568]\n","  reply: nous avons besoin de\n","Epoch  31 Batch  810/8076 - Train Accuracy: 0.1375, Validation Accuracy: 0.1927, Loss: 1.2373\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [375, 39317, 12497, 42218, 13413, 50242]\n","  reply: estce que cela est bien <EOS>\n","Epoch  31 Batch  840/8076 - Train Accuracy: 0.1521, Validation Accuracy: 0.1771, Loss: 0.9151\n","Input\n","  Word Ids:      [30590, 17471]\n","  input : ['go', 'there']\n","\n","Prediction\n","  Word Ids:      [30387, 47458, 50184, 16568]\n","  reply: nous avons besoin de\n","Epoch  31 Batch  870/8076 - Train Accuracy: 0.2670, Validation Accuracy: 0.1771, Loss: 1.1918\n","Input\n","  Word Ids:      [13581, 3441, 1271, 18321]\n","  input : ['what', 'are', 'you', 'doing']\n","\n","Prediction\n","  Word Ids:      [39317, 7083, 6653, 50242, 0, 0, 0, 0]\n","  reply: que vous faire <EOS> dlocalisations dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch  900/8076 - Train Accuracy: 0.1803, Validation Accuracy: 0.1719, Loss: 1.3786\n","Input\n","  Word Ids:      [13581, 3441, 1271, 18321]\n","  input : ['what', 'are', 'you', 'doing']\n","\n","Prediction\n","  Word Ids:      [39317, 7083, 6653, 50242, 0, 0, 0, 0]\n","  reply: que vous faire <EOS> dlocalisations dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch  930/8076 - Train Accuracy: 0.1808, Validation Accuracy: 0.1875, Loss: 1.2933\n","Input\n","  Word Ids:      [10225, 18602, 21422]\n","  input : ['want', 'some', 'food']\n","\n","Prediction\n","  Word Ids:      [30387, 47458, 50184, 16568, 17916, 43428]\n","  reply: nous avons besoin de la scurit\n","Epoch  31 Batch  960/8076 - Train Accuracy: 0.2083, Validation Accuracy: 0.1667, Loss: 1.3106\n","Input\n","  Word Ids:      [30590, 17471]\n","  input : ['go', 'there']\n","\n","Prediction\n","  Word Ids:      [30387, 47458, 50184, 16568]\n","  reply: nous avons besoin de\n","Epoch  31 Batch  990/8076 - Train Accuracy: 0.2955, Validation Accuracy: 0.1719, Loss: 1.4868\n","Input\n","  Word Ids:      [16892, 33605]\n","  input : ['get', 'up']\n","\n","Prediction\n","  Word Ids:      [30387, 47458, 50184, 16568]\n","  reply: nous avons besoin de\n","Epoch  31 Batch 1020/8076 - Train Accuracy: 0.1250, Validation Accuracy: 0.1510, Loss: 1.5443\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [17753, 17916, 36326, 39317, 7083, 2777]\n","  reply: cest la question que vous avez\n","Epoch  31 Batch 1050/8076 - Train Accuracy: 0.2109, Validation Accuracy: 0.1667, Loss: 1.3228\n","Input\n","  Word Ids:      [30590, 17471]\n","  input : ['go', 'there']\n","\n","Prediction\n","  Word Ids:      [30387, 47458, 646, 16568]\n","  reply: nous avons fait de\n","Epoch  31 Batch 1080/8076 - Train Accuracy: 0.2236, Validation Accuracy: 0.1667, Loss: 1.3632\n","Input\n","  Word Ids:      [16892, 33605]\n","  input : ['get', 'up']\n","\n","Prediction\n","  Word Ids:      [30387, 47458, 646, 16568]\n","  reply: nous avons fait de\n","Epoch  31 Batch 1110/8076 - Train Accuracy: 0.1746, Validation Accuracy: 0.1615, Loss: 1.3078\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [17753, 17916, 36326, 39317, 7083, 2777]\n","  reply: cest la question que vous avez\n","Epoch  31 Batch 1140/8076 - Train Accuracy: 0.1667, Validation Accuracy: 0.1406, Loss: 1.2503\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [17753, 17916, 36326, 39317, 7083, 2777]\n","  reply: cest la question que vous avez\n","Epoch  31 Batch 1170/8076 - Train Accuracy: 0.1362, Validation Accuracy: 0.1458, Loss: 1.3677\n","Input\n","  Word Ids:      [10225, 18602, 21422]\n","  input : ['want', 'some', 'food']\n","\n","Prediction\n","  Word Ids:      [30588, 115, 22204, 2649, 16568, 43428]\n","  reply: ce sont des questions de scurit\n","Epoch  31 Batch 1200/8076 - Train Accuracy: 0.2115, Validation Accuracy: 0.1354, Loss: 1.5426\n","Input\n","  Word Ids:      [13581, 3441, 1271, 18321]\n","  input : ['what', 'are', 'you', 'doing']\n","\n","Prediction\n","  Word Ids:      [39317, 646, 17916, 1338, 50242, 0, 0, 0]\n","  reply: que fait la commission <EOS> dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch 1230/8076 - Train Accuracy: 0.2260, Validation Accuracy: 0.1458, Loss: 1.4115\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [32633, 7083, 29483, 50242, 0, 0]\n","  reply: je vous remercie <EOS> dlocalisations dlocalisations\n","Epoch  31 Batch 1260/8076 - Train Accuracy: 0.2139, Validation Accuracy: 0.1615, Loss: 1.2997\n","Input\n","  Word Ids:      [13581, 3441, 1271, 18321]\n","  input : ['what', 'are', 'you', 'doing']\n","\n","Prediction\n","  Word Ids:      [39317, 646, 50242, 0, 0, 0, 0, 0]\n","  reply: que fait <EOS> dlocalisations dlocalisations dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch 1290/8076 - Train Accuracy: 0.2143, Validation Accuracy: 0.1406, Loss: 1.3252\n","Input\n","  Word Ids:      [16892, 33605]\n","  input : ['get', 'up']\n","\n","Prediction\n","  Word Ids:      [12497, 646, 34215, 50242]\n","  reply: cela fait dfaut <EOS>\n","Epoch  31 Batch 1320/8076 - Train Accuracy: 0.1858, Validation Accuracy: 0.1406, Loss: 1.1315\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [17753, 17916, 36326, 39317, 30387, 47458]\n","  reply: cest la question que nous avons\n","Epoch  31 Batch 1350/8076 - Train Accuracy: 0.1528, Validation Accuracy: 0.1354, Loss: 1.2694\n","Input\n","  Word Ids:      [13581, 3441, 1271, 18321]\n","  input : ['what', 'are', 'you', 'doing']\n","\n","Prediction\n","  Word Ids:      [39317, 30387, 50243, 50242, 0, 0, 0, 0]\n","  reply: que nous <UNK> <EOS> dlocalisations dlocalisations dlocalisations dlocalisations\n","Epoch  31 Batch 1380/8076 - Train Accuracy: 0.1049, Validation Accuracy: 0.1562, Loss: 1.7760\n","Input\n","  Word Ids:      [13581, 3441, 1271, 18321]\n","  input : ['what', 'are', 'you', 'doing']\n","\n","Prediction\n","  Word Ids:      [30588, 39317, 30387, 47458, 646, 50242]\n","  reply: ce que nous avons fait <EOS>\n","Epoch  31 Batch 1410/8076 - Train Accuracy: 0.1920, Validation Accuracy: 0.1615, Loss: 1.3133\n","Input\n","  Word Ids:      [10225, 18602, 21422]\n","  input : ['want', 'some', 'food']\n","\n","Prediction\n","  Word Ids:      [30588, 115, 22204, 2649, 16568, 43428]\n","  reply: ce sont des questions de scurit\n","Epoch  31 Batch 1440/8076 - Train Accuracy: 0.1581, Validation Accuracy: 0.1667, Loss: 1.2423\n","Input\n","  Word Ids:      [3959, 3441, 1271]\n","  input : ['how', 'are', 'you']\n","\n","Prediction\n","  Word Ids:      [32633, 4497, 39317, 12497, 42218, 13413]\n","  reply: je pense que cela est bien\n","Epoch  31 Batch 1470/8076 - Train Accuracy: 0.1542, Validation Accuracy: 0.1406, Loss: 1.5005\n","Input\n","  Word Ids:      [10225, 18602, 21422]\n","  input : ['want', 'some', 'food']\n","\n","Prediction\n","  Word Ids:      [30588, 115, 22204, 2649, 16568, 43428]\n","  reply: ce sont des questions de scurit\n"],"name":"stdout"}]},{"metadata":{"id":"u4IYaYX5rgNb","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"IdbdSIgUlsSe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"630726d2-1d19-45d4-adf0-0ffd3dc67bbf","executionInfo":{"status":"ok","timestamp":1534675811464,"user_tz":-330,"elapsed":2255,"user":{"displayName":"mohit saini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115150600458756568924"}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.Trash',\n"," 'translation.ipynb',\n"," 'preprocess_en_fr.p',\n"," 'translation_raw_data',\n"," 'checkpoints',\n"," 'com.google.android.tts-1.apk',\n"," 'Root Nokia X v1.1.2.2 - YouTube.mp4',\n"," 'nokia x toolkit',\n"," 'How to get started with Drive']"]},"metadata":{"tags":[]},"execution_count":42}]},{"metadata":{"id":"353S36kItOEC","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_preprocess():\n","    with open('drive/preprocess_en_fr.p', mode='rb') as in_file:\n","        return pickle.load(in_file)\n","\n","\n","(source_int_text, target_int_text), (source_int_to_vocab, target_int_to_vocab) , (source_vocab_to_int, target_vocab_to_int) = load_preprocess()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UdQB24-9vmM1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"24af34e5-73a5-4b48-f56c-0373b485f0cf","executionInfo":{"status":"ok","timestamp":1534796864866,"user_tz":-330,"elapsed":1095,"user":{"displayName":"hemlata saini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"105515696648587539159"}}},"cell_type":"code","source":["for word in source_int_text[10]:\n","  print(source_int_to_vocab[word])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["stop\n","digging\n"],"name":"stdout"}]},{"metadata":{"id":"N8aE5-M7vsId","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"9507d3db-98dc-4949-e9b5-c9d310bd35c6","executionInfo":{"status":"ok","timestamp":1534796866982,"user_tz":-330,"elapsed":1093,"user":{"displayName":"hemlata saini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"105515696648587539159"}}},"cell_type":"code","source":["for word in target_int_text[10]:\n","  print(target_int_to_vocab[word])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["arrtez\n","de\n","creuser\n","<EOS>\n"],"name":"stdout"}]},{"metadata":{"id":"iVe9o1rfvuXS","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}